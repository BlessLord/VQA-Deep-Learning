{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Input, InputLayer\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoFiles = glob.glob('../deep-dataset/numpys/*.npy')\n",
    "mosFiles = [i for i in videoFiles if 'mos' in i]\n",
    "videoFiles = [i for i in videoFiles if 'mos' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator():\n",
    "    while True:\n",
    "        index_list = random.sample(range(1, 700), 2)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            #print(i, index_list)\n",
    "            f = videoFiles[i]\n",
    "            s = f[:-4]+'_mos.npy'\n",
    "            a = np.load(f)\n",
    "            b = np.load(s)\n",
    "            alldata_x.append(a)\n",
    "            alldata_y.append(b)\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        #print(alldata_x.shape, alldata_y.shape)\n",
    "        yield alldata_x, alldata_y\n",
    "# x = myGenerator()\n",
    "# xtrain, ytrain = next(x)\n",
    "# print('xtrain shape:',xtrain.shape)\n",
    "# print('ytrain shape:',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n",
      "(200, 68, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(videoFiles))\n",
    "for i in videoFiles:\n",
    "    print(np.load(i).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 68\n",
    "width = 120\n",
    "input_shape=(200, height, width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySegNet(input_shape):\n",
    "    base_model  = MobileNet(input_shape=(224,224,3), include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    model = Sequential();\n",
    "    #model.add(InputLayer(input_shape=input_shape))\n",
    "    model.add(TimeDistributed(cnn_model, input_shape=input_shape))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    #model.add(cnn_model)\n",
    "    #model.add(Flatten())\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=False))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(optimizer = optimizers.Adam(lr=0.00001), loss='categorical_crossentropy')\n",
    "    print(model.summary())\n",
    "    return model \n",
    "#mySegNet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_13 (TimeDis (None, 200, 1024)         3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 200, 1024)         0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 512)               3147776   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,379,205\n",
      "Trainable params: 6,357,317\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = mySegNet(input_shape)\n",
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=20, epochs=50)\n",
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=20, epochs=50)\n",
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=20, epochs=50)\n",
    "model.save('model1.h5')\n",
    "model.save_weights('model_weights1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTestDataGenerator():\n",
    "    while True:\n",
    "        index_list = random.sample(range(700, 800), 2)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            #print(i, index_list)\n",
    "            f = videoFiles[i]\n",
    "            s = f[:-4]+'_mos.npy'\n",
    "            a = np.load(f)\n",
    "            b = np.load(s)\n",
    "            alldata_x.append(a)\n",
    "            alldata_y.append(b)\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        #print(alldata_x.shape, alldata_y.shape)\n",
    "        yield alldata_x, alldata_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(200, height, width, 3)\n",
    "model = mySegNet(input_shape)\n",
    "model.load_weights('model_weights1.h5')\n",
    "predictions = []\n",
    "ytrue = []\n",
    "for i in range(0, 100, 2):\n",
    "    x = myTestDataGenerator()\n",
    "    xtest, ytest = next(x)\n",
    "    ytrue.append(ytest)\n",
    "    pred = model.predict(xtest, batch_size=2)\n",
    "    for p in pred:\n",
    "        predictions.append(p)\n",
    "print('predictions shape: ', np.array(predictions).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "Y = []\n",
    "for i in ytrue:\n",
    "    for j in i:\n",
    "        Y.append(j)\n",
    "print(np.array(Y).shape)\n",
    "print(np.array(predictions).shape)\n",
    "t = []\n",
    "p = []\n",
    "for vals in Y:\n",
    "    for i, val in enumerate(vals):\n",
    "        if val != 0:\n",
    "            t.append(i)\n",
    "for vals in predictions:\n",
    "    for i, val in enumerate(vals):\n",
    "        if val == max(vals):\n",
    "            p.append(i)\n",
    "print(t, p)\n",
    "print(accuracy_score(t, p))\n",
    "print(precision_score(t, p, average='macro'))\n",
    "print(recall_score(t, p, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]] [[0.00560889 0.02686344 0.6194726  0.34476787 0.00328722]\n",
      " [0.0229902  0.00351662 0.01547285 0.01837347 0.93964684]]\n"
     ]
    }
   ],
   "source": [
    "x = myGenerator()\n",
    "xtest, ytest = next(x)\n",
    "pred = model.predict(xtest)\n",
    "print(ytest, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
